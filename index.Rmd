---
title: "What to Focus on when Creating an Android Application"
author: "Akramjit S. Sandhu"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1 Introduction

Have you ever wanted to make a mobile application? With the recent release of the Flutter API, now it is a lot easier to make cross platform applications for IOS and Android. Added to this, with React Native and Xamarin, you can easily create cross platform apps with one single code base. Then, if you make an app, what points should you focus on to maximize your apps rating and number of downloads and how do other factors in your application reflect these two items. We proceed to show you several statistics that will assist you when creating your new app. In particular, we will be focusing on the Android ecosystem because there are many more Android phone in use compared to IOS worldwide.

# 2 Setting up your Dataset

## 2.1 Download your Dataset

We will be downloading our dataset from [Kaggle: Google Play Store Apps](https://www.kaggle.com/lava18/google-play-store-apps). To get the CSV dataset, we will we downloading the zip file with mutliple formats for the data and we want to extract and then use the csv one. Then, we place that in our project directory. 

## 2.2 Libraries being used

In our project, we will be using several libraries that have been listed below

```{r echo=TRUE, message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(tidyverse)
library(broom)
```

## 2.3 Inspecting our data

We proceed to load the csv file into memory and check its columns

```{r}
# load the csv into our dataframe called data
data <- read_csv("googleplaystore.csv")
# print out the first few lines to be able to see what kind of data we have
data %>% head()
```

When loading our data, one row could not be added to the data. These will be ignored for the fact that our dataset has over 10,000 data points.

The representation of our columns in our data is as follows: \
    Column name       Description \
 1) App -             The application name of the program \
 2) Category -        The category the program is tailered towards \
 3) Rating -          The score that the program has on the Google Play Store \
 4) Reviews -         The number of reviews the program has on teh Google Play Store\
 5) Size -            The amount of bytes in memory that the application takes up\
 6) Installs -        A lower bound on the number of people who have installed this program\
 7) Type -            The payment type of the application(Paid or Free)\
 8) Price -           The price of the program, 0 if it is free\
 9) Content Rating -  Age group that the program is targeting\
10) Genres -          Several genres the program belongs to\
11) Last Updated -    Date when of last update\
12) Current Ver -     Current version of the program\
13) Android Ver -     Minimum Android version required to run the program\
NOTE: The above data is relevant up to the date the data was updated which is Febuary 3, 2019. 

Our data has several problems like missing values indicated by NaN and mislabled data.

## 2.4 Tidying our data

### 2.4.1 Removing Paid programs

We first set up our data to be processed by removing the programs that are not Free so that we can modify relavant columns and rows later

```{r}
# amount of data points before row removals
data %>% nrow()
# removing not "Free" rows
data <- data %>% filter(Type == "Free")
# checking how many rows remain
data %>% nrow()
```

Due to this, we remove about 800 rows which is less than 10% of our data points. This leaves us with more than 10,000 data points which should be sufficient for our analysis.

### 2.4.2 Removing unneed columns

The next thing we will do to tidy up our data would be to remove columns we will not be using during our analysis. These columns are: \
   Column        Reason to Drop \
1) App -         The name of the program is up to the creator to decide\
2) Size -        Will not be important in our analysis\
3) Type -        All the programs will be free in our data\
4) Price -       All the programs will be free in our data\
5) Genres -      Category is a more focused indicator compared to this\
6) Current Ver - We want to know if the program has potential to be good from the start, not after several versions\

```{r}
# removing the above selected columns from data
data <- data %>% select(-App, -Size, -Type, -Price, -Genres, -`Current Ver`)
# show the remaining columns in the data
data %>% head()
```

### 2.4.3 Removing NaN values

Now we will remove rows which don't have a value some of their column(s)

```{r}
# the number of data points before row removal
data %>% nrow()
# removing rows with NaN values
data <- data[rowSums(is.na(data)) == 0,]
# finding out how many rows remain after NaN values are removed
data %>% nrow()
```

Since we still will have 8,000 data points, it is sufficient to continue our analysis.

### 2.4.4 Removing unneeded rows

We will be removing rows where the program is unrated as we cannot gauge a proper target audience without rating

```{r}
# the number of data points before row removal
data %>% nrow()
# removing rows where content is unrated
data <- data %>% filter(`Content Rating` != "Unrated")
# checking how many rows remain
data %>% nrow()
```

Because of this, one row is lost but we still have a sufficient number of data points for our analysis.

### 2.4.5 Restructuring our data

Here we reinterpret Last Updated as how many days ago from dataset creaton on Kraggle did the last update happen. 

```{r}
# create new column that calculates days since last update
data <- data %>% mutate(Days = as.numeric(strptime("February 3, 2019", format="%B %d, %Y") - strptime(`Last Updated`, format="%B %d, %Y")))
# remove column Last Updated as it is no longer needed
data <- data %>% select(-`Last Updated`)
# show the new columns in data
data %>% head()
```

Due to wanting to program with modern Android features that are compatible with almost all Android devices, greater than 95% of them, we limit Android version to be atleast 4.4. We also exclude the ambiguous category called "Varies with device" to be able to better make results from our data

```{r}
# number of data points before row removal
data %>% nrow()
# removing unneeded Android Ver programs
data <- data %>% filter(substr(`Android Ver`, 1, 3) >= 4.4) %>%
  filter(`Android Ver` != "Varies with device")
# number of data points remaining
data %>% nrow()
```

With this requirement, we have removed most of the data points in our data variable but leaves us with atleast 1,400 data points. This is sufficient for our analysis. 

Now we wish to set the soonest data point to update as day zero, which is the date the data was gathered into a table before being put on Kaggle. Then we only want to look at data that was updated within the last 2 months from that as we will be actively updating our application

```{r}
# decrease the value of days to reflect the distance from day of dataset updload and how long between updates
data <- data %>% mutate(Days = Days - min(Days))
# print the number of data points before we limit to just the last 2 months
data %>% nrow()
data <- data %>% filter(Days < 60.0)
# print the number of data points after we limitted Days
data %>% nrow()
```

This leaves us with almost 1,000 data points which is still sufficient for our analysis.

Now we will turn the Installs column into a numeric column as follows for easy manipulation later

```{r}
# turning Installs into a numeric type by removing "," and "+"
data <- data %>% transform(Installs = as.numeric(str_replace_all(Installs, "[,+]", "")))
```

# 3 Exploratory Data Analysis

## 3.1 Summary Statistics

NOTE: In the following graphs, I display mean as the blue line; first, second, and third quartile as the red lines; and the appropriate standard deviations for the graph in purple lines.

We will use the following function to calculate skewness of some of our data. This function was provided in lecture notes 22.

```{r}
compute_skew_stat <- function(df, attribute) {
  attribute <- enquo(attribute)
  
  df %>%
    summarize(med_attr=median(!!attribute, na.rm=TRUE), 
              q1_attr=quantile(!!attribute, 1/4, na.rm=TRUE), 
              q3_attr=quantile(!!attribute, 3/4, na.rm=TRUE)) %>%
    mutate(d1 = med_attr - q1_attr, d2 = q3_attr - med_attr, skew_stat = d1 - d2) %>%
    select(d1, d2, skew_stat)
}
```

### 3.1.1 Statistics for Days

We now show summary statistics and their corresponding graph for Days

```{r, warning=FALSE}
# calculating quartile statistics
quartile_df <- data %>%
  summarise(first=quantile(data$Days, p=1/4),
            second=quantile(data$Days, p=1/2),
            third=quantile(data$Days, p=3/4)) %>%
  tidyr::gather(quartile, value)

# calculating standard deviations from mean and printing them
sd_df <- data %>%
  summarize(mean_days = mean(Days), sd_days = sd(Days)) %>%
  slice(rep_along(seq(-3, 3), 1)) %>%
  mutate(sd_to_plot=seq(-3, 3)) %>%
  mutate(sd_val = mean_days + sd_to_plot * sd_days)
sd_df %>% select(sd_to_plot, sd_val)

# printing several statistics
summary(data$Days)

# graphing the above calculated statistics on Days
data %>%
  ggplot(aes(x=Days)) + 
  geom_histogram(bins = 60) + 
  geom_vline(aes(xintercept=value), data=quartile_df, 
             color = "red") + 
  geom_vline(aes(xintercept=mean(data$Days)), color = "blue") +
  geom_vline(aes(xintercept = sd_val), data=filter(sd_df, sd_val >= 0),
               linetype=2, color="purple") + 
  labs(title="Frequency of days from last update", x = "Days from last update", y="Count")

# calculating skew
data %>% compute_skew_stat(Days)

```

As we can see, the Days dataset is skewed right as the distance from first quartile to second quartile is more than half the distance from second quartile to third quartile. On top of that, the absolute value of our skewness is greater than 1, thus our Days dataset is in fact skewed. 

### 3.1.2 Statistics for Reviews

We now show summary statistics and their corresponding graph for Reviews

```{r, warning=FALSE}
# calculating quartile statistics
quartile_df <- data %>%
  summarise(first=quantile(data$Reviews, p=1/4),
            second=quantile(data$Reviews, p=1/2),
            third=quantile(data$Reviews, p=3/4)) %>%
  tidyr::gather(quartile, value)

# calculating standard deviations from mean and printing them
sd_df <- data %>%
  summarize(mean_reviews = mean(Reviews), sd_reviews = sd(Reviews)) %>%
  slice(rep_along(seq(-3, 3), 1)) %>%
  mutate(sd_to_plot=seq(-3, 3)) %>%
  mutate(sd_val = mean_reviews + sd_to_plot * sd_reviews)
sd_df %>% select(sd_to_plot, sd_val)

# printing several statistics
summary(data$Reviews)

# graphing the above calculated statics on Reviews limiting that reviews be less than 2 x 10^7 so all our statistics can fit on the plot reasonably
data %>% filter(Reviews < 20000000) %>%
  ggplot(aes(x=Reviews)) + 
  geom_histogram(bins = 60) + 
  geom_vline(aes(xintercept=value), data=quartile_df, 
             color = "red") + 
  geom_vline(aes(xintercept=mean(data$Reviews)), color = "blue") +
  geom_vline(aes(xintercept = sd_val), data=filter(sd_df, sd_val >= 0),
               linetype=2, color="purple") + 
  labs(title="Frequency of Reviews", x = "Reviews", y="Count")

# calculating skew
data %>% compute_skew_stat(Reviews)

```

As we can see, the Reviews dataset is skewed right as the distance from first quartile to second quartile is several times shorter than the distance from second quartile to third quartile. On top of that, the absolute value of our skewness is greater than 1, thus our Reviews dataset is in fact skewed. 

### 3.1.3 Statistics for Installs

We now show summary statistics and their corresponding graph for Installs

```{r, warning=FALSE}
# calculating quartile statistics
quartile_df <- data %>%
  summarise(first=quantile(data$Installs, p=1/4),
            second=quantile(data$Installs, p=1/2),
            third=quantile(data$Installs, p=3/4)) %>%
  tidyr::gather(quartile, value)

# calculating standard deviations from mean and printing them
sd_df <- data %>%
  summarize(mean_installs = mean(Installs), sd_installs = sd(Installs)) %>%
  slice(rep_along(seq(-3, 3), 1)) %>%
  mutate(sd_to_plot=seq(-3, 3)) %>%
  mutate(sd_val = mean_installs + sd_to_plot * sd_installs)
sd_df %>% select(sd_to_plot, sd_val)

# printing several statistics
summary(data$Installs)

# graphing the above calculated statistics on Installs
data %>%
  ggplot(aes(x=Installs)) + 
  geom_histogram(bins = 60) + 
  geom_vline(aes(xintercept=value), data=quartile_df, 
             color = "red") + 
  geom_vline(aes(xintercept=mean(data$Installs)), color = "blue") +
  geom_vline(aes(xintercept = sd_val), data=filter(sd_df, sd_val >= 0),
               linetype=2, color="purple") + 
  labs(title="Frequency of Installs", x = "Installs", y="Count")

# calculating skew
data %>% compute_skew_stat(Installs)

```

As we can see, the Installs dataset is skewed left as the distance from first quartile to second quartile is five times longer than the distance from second quartile to third quartile. On top of that, the absolute value of our skewness is greater than 1, thus our Installs dataset is in fact skewed. 

### 3.1.4 Statistics for Rating

We now show summary statistics and their corresponding graph for Rating

```{r, warning=FALSE}
# calculating quartile statistics
quartile_df <- data %>%
  summarise(first=quantile(data$Rating, p=1/4),
            second=quantile(data$Rating, p=1/2),
            third=quantile(data$Rating, p=3/4)) %>%
  tidyr::gather(quartile, value)

# calculating standard deviations from mean and printing them
sd_df <- data %>%
  summarize(mean_rating = mean(Rating), sd_rating = sd(Rating)) %>%
  slice(rep_along(seq(-3, 3), 1)) %>%
  mutate(sd_to_plot=seq(-3, 3)) %>%
  mutate(sd_val = mean_rating + sd_to_plot * sd_rating)
sd_df %>% select(sd_to_plot, sd_val)

# printing several statistics
summary(data$Rating)

# graphing the above calculated statistics on Rating
data %>%
  ggplot(aes(x=Rating)) + 
  geom_histogram(bins = 60) + 
  geom_vline(aes(xintercept=value), data=quartile_df, 
             color = "red") + 
  geom_vline(aes(xintercept=mean(data$Rating)), color = "blue") +
  geom_vline(aes(xintercept = sd_val), data=filter(sd_df, sd_val >= 0),
               linetype=2, color="purple") + 
  labs(title="Frequency of Rating", x = "Rating", y="Count")

# calculating skew
data %>% compute_skew_stat(Rating)

```

As we can see, the Ratings Dataset does not seem to be skewed in either direction. This is because the distance from the first quartile to the second quartile is the same from the second quartile to the third quartile. On top of that, the absolute value of our skewness is less than 1, thus our Rating dataset is in fact not skewed. 

## 3.2 Skew corrections of graphs

In this section, we attempt to graph the several skewed datasets by log shifting them and then seeing if the resulting datasets are still skewed. 
Here we prepare data with the log shifted calculations

```{r}
# log shift the three skewed data to new columns for later use
data <- data %>% 
  mutate(log_Days = log2(Days + 1)) %>%
  mutate(log_Reviews = log2(Reviews + 1)) %>%
  mutate(log_Installs = log2(Installs + 1))
# display the new columns
data %>% head()
```

### 3.2.1 Log shifted Days

We now attempt to see if log shifting Days allows the data to not be skewed and graph the resulting data

```{r}
# graphing the log shifted data
data %>%
  ggplot(aes(x=log_Days)) + 
  geom_histogram(bins = 60) + 
  labs(title="Frequency of Log Shifted Days", x = "Log Shifted Days", y="Count")

# calculating skew of log shifted data
data %>% compute_skew_stat(log_Days)

```

Since the absolute value of skew is less than 1, then the log shifted Days dataset is a better dataset to make inferences on. 

### 3.2.2 Log shifted Reviews

We now attempt to see if log shifting Reviews allows the data to not be skewed and graph the resulting data

```{r}
# graphing the log shifted data
data %>%
  ggplot(aes(x=log_Reviews)) + 
  geom_histogram(bins = 60) + 
  labs(title="Frequency of Log Shifted Reviews", x = "Log Shifted Reviews", y="Count")

# calculating skew of log shifted data
data %>% compute_skew_stat(log_Reviews)

```

Since the absolute value of skew is greater than 1, then the log shifted Days dataset is not a better dataset to use then before log shifting the Reviews dataset.

### 3.2.3 Log shifted Installs

We now attempt to see if log shifting Installs allows the data to not be skewed and graph the resulting data

```{r}
# graphing the log shifted data
data %>%
  ggplot(aes(x=log_Installs)) + 
  geom_histogram(bins = 60) + 
  labs(title="Frequency of Log Shifted Installs", x = "Log Shifted Installs", y="Count")

# calculating skew of log shifted data
data %>% compute_skew_stat(log_Installs)

```

Since the absolute value of skew is less than 1, then the log shifted Days dataset is a better dataset to make inferences on. 

# 3.2.4 Readjusting our data

We now readjust our data depending on if our original skewed dataset could be transformed by a log shift to a data set that is not skewed

```{r}
# remove Days and Installs as their log shifter versions are better to use
data <- data %>% select(-Days, -Installs)

# remove the log shifted version of reviews because it is not better than Reviews
data <- data %>% select(-log_Reviews)

# print out our current columns
data %>% head()
```

## 3.3 Hypothesis Testing 

We use 5% for our threshold as is standard in statistics and for our class for hypothesis testing.

### 3.3.1 Testing Installs based on Ratings

I hypothesis that the number of installs is dependant on a high rating, in this case a rating of greater than or equal to 4.0. Then, we can create a null hypothesis to test this as: a rating of less than 4.0 does not change the amount of install we get. More formally, 
$$ 
H_0: \text{Getting a low rating has no effect on installs} \to \mu = \mu_{\text{Installs}} \\
H_1: \text{Getting a low rating has an effect on installs} \to \mu \ne \mu_{\text{Installs}}
$$
Then, in our setup, we use the Reviews column in data for the reviews information and log_Installs for Installs as it can be approximated by a normal curve. Now, assuming $H_0$, 

```{r}
# calculate the mean of installs in our data
mean_installs <- mean(data$log_Installs)
mean_installs

# calculate the mean and sample standard deviation for installs when rating in low
temp <- data %>% filter(Rating < 4.0)
mean_rating <- mean(temp$log_Installs)
mean_rating
sd_rating <- sd(temp$log_Installs) / sqrt(length(temp$log_Installs))
sd_rating

# now we calculate the z-score of getting our mean of installs when rating is low against the mean of all installs using the sample standard deviation of installs when ratings is low
z_score <- (mean_installs - mean_rating) / sd_rating
z_score
```

Because the z score that we calculated for our hull hypothesis testing was over 5 standard deviations from the mean of installs when ratings is low, then the probability of this event occurring is much less than 5%, thus we can reject the $H_0$ and accept $H_1$. 

### 3.3.2 Testing Ratings based on Days since last update

I hypothesis that the value of Rating is dependant on less time between updates, in this case we decide that is 7 days. Then, we can create a null hypothesis to test this as: the amount of days being more than 7 from last update has no effect on Rating. More formally, 
$$ 
H_0: \text{Long time between updates has no effect on Rating} \to \mu_{\text{Days}} = \mu_{\text{Rating}} \\
H_1: \text{Long time between updates has an effect on Rating} \to \mu_{\text{Days}} \ne \mu_{\text{Rating}}
$$
Then, in our setup, we use the log_days column in data for the Days as it can be well approximated by a normal curve. I use the Rating column to stand for the rating. Now, assuming $H_0$, 

```{r}
# calculate the mean of Rating in our data
mean_installs <- mean(data$Rating)
mean_installs

# calculate the mean and sample standard deviation for Rating when Days is greater than 7
temp <- data %>% filter(log_Days > log2(7.0 + 1))
mean_rating <- mean(temp$Rating)
mean_rating
sd_rating <- sd(temp$Rating) / sqrt(length(temp$Rating))
sd_rating

# now we calculate the z-score of getting our mean of rating when days is large against the mean of all ratings using the sample standard deviation of Rating when Days is large
z_score <- (mean_installs - mean_rating) / sd_rating
z_score
```

Because the z score that we calculated for our hull hypothesis testing was under 2 standard deviations from the mean of Ratings when Days is large, then the probability of this event occurring is much greater than 5%, thus we accept the $H_0$ and instead reject $H_1$.

# 4 Machine Learning analysis

## 4.1 Linear Regression

We will now attempt to put linear regression models to approximate several data values and see how if there is a correlation between predictors and responses in our models. 

### 4.1.1 Linear Regression statistics on Ratings

We now try to fit a linear regression line to our data for Ratings. We then see what values from our model we believe are statistically significant enough to include in our final model as proper indicators that reflect change in Ratings. 

```{r, warning=FALSE}
# fit a line to our data with Rating being output and the rest of the variables being input. 
fit_ratings <- lm(Rating~1 + ., data=data) %>% tidy()

# select only the variables that have a statistics effect on Rating to be in our linear model so it is easier to see what effects model
fit_ratings <- fit_ratings %>% filter(p.value >= 0.05)
fit_ratings %>% knitr::kable()
```

Thus, we are now statistically confident that ratings will improve or decrease according to our model by the amount corresponding to the estimate of our term. Thus, Categories like COMICS, EDUCATION, and  PHOTOGRAPHY, among many others improve the Rating of a program. Other Categories like ENTERTAINMENT, FAMILY, and PARENTING, among many others, decline the Rating of a program. Beyond Categories, the Content Rating of an app will decrease the Rating of your program but choosing EVERYONE for this will demote it the least. The optimal Android Version that should be supported is atleast 5.1 with 4.4W coming as runner up. We also see that the number of installs that your program has can positively effect your programs Rating. 

### 4.1.2 Linear Regression statistics on Installs

We now try to fit a linear regression line to our data for Installs. We then see what values from our model we believe are statistically significant enough to include in our final model as proper indicators that reflect change in Ratings. Because we are representing Installs by its log shifted equivalence, we acknowledge that increases and decreases in log_Installs correspond to increases or decreases in Installs which lets us easily interpret the following results. 

```{r, warning=FALSE}
# fit a line to our data with Rating being output and the rest of the variables being input. 
fit_installs <- lm(log_Installs~1 + ., data=data) %>% tidy()

# select only the variables that have a statistics effect on Rating to be in our linear model so it is easier to see what effects model
fit_installs <- fit_installs %>% filter(p.value >= 0.05)
fit_installs %>% knitr::kable()
```

Thus, we are now statistically confident that installs will improve or decrease according to our model by the amound corresponding to reversing the log shift on estimate of our term. As stated, positive and negative estimates correspond to increase and decreases respectively in installs. Thus, Categories like BEAUTY, COMMUNICATION, and GAME, among many others improve the amount of installs of a program. Other Categories like BUSINESS, EVENTS, and FAMILY, among many others decline the amount of installs of a program. Beyond Categories, the Rating of a program will increase the amount of Installs. The content Rating of a program will improve installs the most if chosen to be EVERYONE 10+ and decreases installs the most if it is instead chosen to be EVERYONE. The Android ver that should be supported to best increase the number of installs is 7.1 and the one that most decreases the number of installs is 4.4W. 

# 5 Conclusion

We have models that tell us with statistical confidence that there are properties that improve or decrease Rating and there are properties that improve or decrease Installs. We now show what properties increase both and what properties decrease both.

```{r}
# inner join positive estimate rows from fitting on Ratings and Installs to see what properties increases both
filter(fit_ratings, estimate > 0) %>% inner_join(filter(fit_installs, estimate > 0), by="term") %>% select(term, estimate.x, estimate.y) %>% print(n=1e9, width=1e9)

# inner join negative estimate rows from fitting on Ratings and Installs to see what properties decreases both
filter(fit_ratings, estimate < 0) %>% inner_join(filter(fit_installs, estimate < 0), by="term") %>% select(term, estimate.x, estimate.y) %>% print(n=1e9, width=1e9)
```

Thus, these two tables tell us that the only properties that positively effect both are a subset of the Categories. These are: BEAUTY, EDUCATION, HEALTH AND FITNESS, HOUSE AND HOME, PHOTOGRAPHY, and SHOPPING. 
The properties that negatively effect both are a subset of the Categories: AUTO AND VEHICLES, FAMILY, LIFESTYLE, MAPS AND NAVIGATION, MEDICAL, NEWS AND MAGAZINES PARENTING, and SOCIAL. Also, Content rating being EVERYONE, and Android version being either 5.0 and above, or 7.0 and above also negatively effect both. 

Thus, we have seen how many different properties can effect how the rating of your program and the number of installs it has can vary. We have seen what properties to thrive for to improve rating, or number of installs, or both with statistical confidence. We have also seen how some properties relavant to your program are distributed and what those corresponding distributions are and thus, what you should expect from those values when you launch your program. 




